{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LWsNd3_M3MP"
      },
      "source": [
        "# üê∏ [Coqui-TTS](https://github.com/coqui-ai/TTS)  on CPU Real-Time Speech Synthesis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAqrSIWgLyP0"
      },
      "source": [
        "## Tacotron2 with Dynamic Convolutional Attention\n",
        "Paper: https://arxiv.org/abs/2005.11129\n",
        "\n",
        "Trained with **LJSpeech** for **200K steps** and reduction rate of 2.\n",
        "\n",
        "## Universal FullBand-MelGAN\n",
        "Paper: https://arxiv.org/abs/2005.05106\n",
        "\n",
        "Trained with **LibriTTS** for **675K steps** with real spectrograms.\n",
        "\n",
        "This model is able to synthesize speech in different languages and voices.\n",
        "\n",
        "**Note that** TTS and vocoder models have different sampling rates. This is fixed by\n",
        "interpolating TTS output before Vocoder inference."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ku-dA4DKoeXk"
      },
      "source": [
        "### Download Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGIgnWhGsxU1",
        "outputId": "fc5802a1-6565-45dc-9633-c61cceee1d54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1CFoPDQBnhfBFu2Gc0TBSJn8o-TuNKQn7\n",
            "To: /content/tts_model.pth.tar\n",
            "339MB [00:13, 25.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1lWSscNfKet1zZSJCNirOn7v9bigUZ8C1\n",
            "To: /content/config.json\n",
            "100% 11.7k/11.7k [00:00<00:00, 9.33MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1qevpGRVHPmzfiRBNuugLMX62x1k7B5vK\n",
            "To: /content/scale_stats.npy\n",
            "100% 10.5k/10.5k [00:00<00:00, 16.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown --id 1CFoPDQBnhfBFu2Gc0TBSJn8o-TuNKQn7 -O tts_model.pth.tar\n",
        "!gdown --id 1lWSscNfKet1zZSJCNirOn7v9bigUZ8C1 -O config.json\n",
        "!gdown --id 1qevpGRVHPmzfiRBNuugLMX62x1k7B5vK -O scale_stats.npy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dnpE0-kvTsu",
        "outputId": "4beeb938-6bc2-493e-d87d-663bf5c09b23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1i16_9_qLgtjdT9W5hfB74BlLHihReK87\n",
            "To: /content/vocoder_model.pth.tar\n",
            "109MB [00:04, 22.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1uBRVNxsoCYJxNCqPoQedASm6EtSW3w04\n",
            "To: /content/config_vocoder.json\n",
            "100% 7.51k/7.51k [00:00<00:00, 13.0MB/s]\n",
            "Permission denied: https://drive.google.com/uc?id=1JZugLTx8li1EMgptiXwh4AsOFYrJjobi\n",
            "Maybe you need to change permission over 'Anyone with the link'?\n"
          ]
        }
      ],
      "source": [
        "!gdown --id 1i16_9_qLgtjdT9W5hfB74BlLHihReK87 -O vocoder_model.pth.tar\n",
        "!gdown --id 1uBRVNxsoCYJxNCqPoQedASm6EtSW3w04 -O config_vocoder.json\n",
        "!gdown --id 1JZugLTx8li1EMgptiXwh4AsOFYrJjobi -O scale_stats_vocoder.npy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZuDrj_ioqHE"
      },
      "source": [
        "### Setup Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2axt5BYq7gv",
        "outputId": "a1e19974-915a-42e5-8f92-4ec1cd0262f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  espeak-data libespeak1 libportaudio2 libsonic0\n",
            "The following NEW packages will be installed:\n",
            "  espeak espeak-data libespeak1 libportaudio2 libsonic0\n",
            "0 upgraded, 5 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 1,219 kB of archives.\n",
            "After this operation, 3,031 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libportaudio2 amd64 19.6.0-1 [64.6 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsonic0 amd64 0.2.0-6 [13.4 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 espeak-data amd64 1.48.04+dfsg-5 [934 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libespeak1 amd64 1.48.04+dfsg-5 [145 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 espeak amd64 1.48.04+dfsg-5 [61.6 kB]\n",
            "Fetched 1,219 kB in 1s (938 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 5.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libportaudio2:amd64.\n",
            "(Reading database ... 160772 files and directories currently installed.)\n",
            "Preparing to unpack .../libportaudio2_19.6.0-1_amd64.deb ...\n",
            "Unpacking libportaudio2:amd64 (19.6.0-1) ...\n",
            "Selecting previously unselected package libsonic0:amd64.\n",
            "Preparing to unpack .../libsonic0_0.2.0-6_amd64.deb ...\n",
            "Unpacking libsonic0:amd64 (0.2.0-6) ...\n",
            "Selecting previously unselected package espeak-data:amd64.\n",
            "Preparing to unpack .../espeak-data_1.48.04+dfsg-5_amd64.deb ...\n",
            "Unpacking espeak-data:amd64 (1.48.04+dfsg-5) ...\n",
            "Selecting previously unselected package libespeak1:amd64.\n",
            "Preparing to unpack .../libespeak1_1.48.04+dfsg-5_amd64.deb ...\n",
            "Unpacking libespeak1:amd64 (1.48.04+dfsg-5) ...\n",
            "Selecting previously unselected package espeak.\n",
            "Preparing to unpack .../espeak_1.48.04+dfsg-5_amd64.deb ...\n",
            "Unpacking espeak (1.48.04+dfsg-5) ...\n",
            "Setting up libportaudio2:amd64 (19.6.0-1) ...\n",
            "Setting up espeak-data:amd64 (1.48.04+dfsg-5) ...\n",
            "Setting up libsonic0:amd64 (0.2.0-6) ...\n",
            "Setting up libespeak1:amd64 (1.48.04+dfsg-5) ...\n",
            "Setting up espeak (1.48.04+dfsg-5) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "! sudo apt-get install espeak"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZduAf-qYYEIT",
        "outputId": "f8127e51-3ba2-443d-9524-72cdd3875bd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'TTS_repo'...\n",
            "remote: Enumerating objects: 17528, done.\u001b[K\n",
            "remote: Counting objects: 100% (3943/3943), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1365/1365), done.\u001b[K\n",
            "remote: Total 17528 (delta 2830), reused 3461 (delta 2531), pack-reused 13585\u001b[K\n",
            "Receiving objects: 100% (17528/17528), 126.45 MiB | 33.28 MiB/s, done.\n",
            "Resolving deltas: 100% (12489/12489), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/coqui-ai/TTS TTS_repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofPCvPyjZEcT",
        "outputId": "ccbf1e63-0d25-498b-a989-0a23fa4714f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/TTS_repo\n",
            "Note: checking out '4132240'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n",
            "HEAD is now at 41322408 Merge branch 'dev' of https://github.com/mozilla/TTS into dev\n",
            "Requirement already satisfied: torch>=1.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.9.0+cu102)\n",
            "Collecting tensorflow==2.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/eb/18/374af421dfbe74379a458e58ab40cf46b35c3206ce8e183e28c1c627494d/tensorflow-2.3.1-cp37-cp37m-manylinux2010_x86_64.whl (320.4MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 320.4MB 54kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (1.4.1)\n",
            "Collecting numba==0.48\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/39/dc/5ce4a94d98e8a31cab21b150e23ca2f09a7dd354c06a69f71801ecd890db/numba-0.48.0-1-cp37-cp37m-manylinux2014_x86_64.whl (3.5MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.6MB 49.6MB/s \n",
            "\u001b[?25hCollecting librosa==0.7.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/b5/1817862d64a7c231afd15419d8418ae1f000742cac275e85c74b219cbccb/librosa-0.7.2.tar.gz (1.6MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.6MB 44.5MB/s \n",
            "\u001b[?25hCollecting phonemizer>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/6d/fb1757f006b584469bc0b9d56209b2ac873420033133b7da58e49033862e/phonemizer-2.2.2-py3-none-any.whl (49kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 51kB 9.3MB/s \n",
            "\u001b[?25hCollecting unidecode==0.4.20\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/6f/05f5deb753d0594583aa1cc0d2fe9d631d9a00e9b28d0da49f8d3763755b/Unidecode-0.04.20-py2.py3-none-any.whl (228kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 235kB 58.3MB/s \n",
            "\u001b[?25hCollecting attrdict\n",
            "  Downloading https://files.pythonhosted.org/packages/ef/97/28fe7e68bc7adfce67d4339756e85e9fcf3c6fd7f0c0781695352b70472c/attrdict-2.0.1-py2.py3-none-any.whl\n",
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/84/46421bd3e0e89a92682b1a38b40efc22dafb6d8e3d947e4ceefd4a5fabc7/tensorboardX-2.2-py2.py3-none-any.whl (120kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 122kB 57.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (3.2.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (7.1.2)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (1.1.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 14)) (4.41.1)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 15)) (2.1.0)\n",
            "Collecting bokeh==1.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/70/fdd4b186d8570a737372487cc5547aac885a1270626e3ebf03db1808e4ed/bokeh-1.4.0.tar.gz (32.4MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32.4MB 110kB/s \n",
            "\u001b[?25hCollecting pysbd\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/0a/c99fb7d7e176f8b176ef19704a32e6a9c6aafdf19ef75a187f701fc15801/pysbd-0.3.4-py3-none-any.whl (71kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 71kB 11.3MB/s \n",
            "\u001b[?25hCollecting pyworld\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/0b/9f8ceb7548bbb1294729b291044b8e72754db21dbc672acbd5eec6ed740b/pyworld-0.3.0.tar.gz (212kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 215kB 61.0MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 19)) (0.10.3.post1)\n",
            "Collecting nose==1.3.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 163kB 55.8MB/s \n",
            "\u001b[?25hCollecting cardboardlint==1.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a8/d4/02c9ad87226867995e8cc89791ba3a5a653e1d25c04263adabe87b7e1472/cardboardlint-1.3.0.tar.gz\n",
            "Collecting pylint==2.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/fb/734960c55474c8f74e6ad4c8588fc44073fb9d69e223269d26a3c2435d16/pylint-2.5.3-py3-none-any.whl (324kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 327kB 51.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 23)) (3.6.4)\n",
            "Collecting umap-learn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/69/85e7f950bb75792ad5d666d86c5f3e62eedbb942848e7e3126513af9999c/umap-learn-0.5.1.tar.gz (80kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 81kB 11.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 25)) (0.29.23)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 26)) (3.13)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.5->-r requirements.txt (line 1)) (3.7.4.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.1->-r requirements.txt (line 2)) (0.12.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.1->-r requirements.txt (line 2)) (1.34.1)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.1->-r requirements.txt (line 2)) (1.6.3)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.1->-r requirements.txt (line 2)) (2.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.1->-r requirements.txt (line 2)) (1.12.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.1->-r requirements.txt (line 2)) (0.36.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.1->-r requirements.txt (line 2)) (3.3.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.1->-r requirements.txt (line 2)) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.1->-r requirements.txt (line 2)) (1.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.1->-r requirements.txt (line 2)) (1.15.0)\n",
            "Collecting gast==0.3.3\n",
            "  Downloading https://files.pythonhosted.org/packages/d6/84/759f5dd23fec8ba71952d97bcc7e2c9d7d63bdc582421f3cd4be845f0c98/gast-0.3.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.1->-r requirements.txt (line 2)) (0.2.0)\n",
            "Collecting tensorflow-estimator<2.4.0,>=2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/ed/5853ec0ae380cba4588eab1524e18ece1583b65f7ae0e97321f5ff9dfd60/tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 460kB 46.8MB/s \n",
            "\u001b[?25hCollecting h5py<2.11.0,>=2.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/c0/abde58b837e066bca19a3f7332d9d0493521d7dd6b48248451a9e3fe2214/h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.9MB 48.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.1->-r requirements.txt (line 2)) (3.12.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba==0.48->-r requirements.txt (line 5)) (57.0.0)\n",
            "Collecting llvmlite<0.32.0,>=0.31.0dev0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/10/d02c0ac683fc47ecda3426249509cf771d748b6a2c0e9d5ebbee76a7b80a/llvmlite-0.31.0-cp37-cp37m-manylinux1_x86_64.whl (20.2MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20.2MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.2->-r requirements.txt (line 6)) (2.1.9)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.2->-r requirements.txt (line 6)) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.2->-r requirements.txt (line 6)) (1.0.1)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.2->-r requirements.txt (line 6)) (4.4.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.2->-r requirements.txt (line 6)) (0.2.2)\n",
            "Requirement already satisfied: attrs>=18.1 in /usr/local/lib/python3.7/dist-packages (from phonemizer>=2.2.0->-r requirements.txt (line 7)) (21.2.0)\n",
            "Collecting segments\n",
            "  Downloading https://files.pythonhosted.org/packages/1e/ae/02d31d73cfc3fa1dc74b7b7f14820fadc287e74406583d7af7b80fcaac41/segments-2.2.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 11)) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 11)) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 11)) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 11)) (1.3.1)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask->-r requirements.txt (line 13)) (1.1.0)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask->-r requirements.txt (line 13)) (2.11.3)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask->-r requirements.txt (line 13)) (1.0.1)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask->-r requirements.txt (line 13)) (7.1.2)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.7/dist-packages (from bokeh==1.4.0->-r requirements.txt (line 16)) (20.9)\n",
            "Requirement already satisfied: tornado>=4.3 in /usr/local/lib/python3.7/dist-packages (from bokeh==1.4.0->-r requirements.txt (line 16)) (5.1.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile->-r requirements.txt (line 19)) (1.14.5)\n",
            "Collecting astroid<=2.5,>=2.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/f0/2364d469327ffef8ee1964a5995f8206fd22fcfa57f2618498f8b963329f/astroid-2.5-py3-none-any.whl (220kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225kB 58.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: toml>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pylint==2.5.3->-r requirements.txt (line 22)) (0.10.2)\n",
            "Collecting isort<5,>=4.2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/b0/c121fd1fa3419ea9bfd55c7f9c4fedfec5143208d8c7ad3ce3db6c623c21/isort-4.3.21-py2.py3-none-any.whl (42kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 51kB 9.7MB/s \n",
            "\u001b[?25hCollecting mccabe<0.7,>=0.6\n",
            "  Downloading https://files.pythonhosted.org/packages/87/89/479dc97e18549e21354893e4ee4ef36db1d237534982482c3681ee6e7b57/mccabe-0.6.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gdown->-r requirements.txt (line 23)) (2.23.0)\n",
            "Collecting pynndescent>=0.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/65/8189298dd3a05bbad716ee8e249764ff8800e365d8dc652ad2192ca01b4a/pynndescent-0.5.2.tar.gz (1.1MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.2MB 31.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.1->-r requirements.txt (line 2)) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.1->-r requirements.txt (line 2)) (0.6.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.1->-r requirements.txt (line 2)) (1.31.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.1->-r requirements.txt (line 2)) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.1->-r requirements.txt (line 2)) (0.4.4)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from segments->phonemizer>=2.2.0->-r requirements.txt (line 7)) (2019.12.20)\n",
            "Collecting clldutils>=1.7.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/99/3ea7e3595e730332c2799938e2dad456916772e571fa0cd8dcdfb9d5780a/clldutils-3.9.0-py2.py3-none-any.whl (195kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 204kB 10.0MB/s \n",
            "\u001b[?25hCollecting csvw>=1.5.6\n",
            "  Downloading https://files.pythonhosted.org/packages/55/ae/afb43a6b88c4202d29e4ec7aca76633d8c530140f4f5a32ee762d07c4607/csvw-1.11.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->flask->-r requirements.txt (line 13)) (2.0.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile->-r requirements.txt (line 19)) (2.20)\n",
            "Collecting lazy-object-proxy>=1.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/b0/f055db25fd68ab4859832a887c8b304274fc12dd5a3f8e83e61250733aeb/lazy_object_proxy-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (55kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 61kB 11.3MB/s \n",
            "\u001b[?25hCollecting typed-ast<1.5,>=1.4.0; implementation_name == \"cpython\" and python_version < \"3.8\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/65/b3/573d2f1fecbbe8f82a8d08172e938c247f99abe1be3bef3da2efaa3810bf/typed_ast-1.4.3-cp37-cp37m-manylinux1_x86_64.whl (743kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 747kB 41.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gdown->-r requirements.txt (line 23)) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gdown->-r requirements.txt (line 23)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gdown->-r requirements.txt (line 23)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gdown->-r requirements.txt (line 23)) (2.10)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.1->-r requirements.txt (line 2)) (4.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.1->-r requirements.txt (line 2)) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.1->-r requirements.txt (line 2)) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.1->-r requirements.txt (line 2)) (4.2.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.1->-r requirements.txt (line 2)) (1.3.0)\n",
            "Collecting colorlog\n",
            "  Downloading https://files.pythonhosted.org/packages/32/e6/e9ddc6fa1104fda718338b341e4b3dc31cd8039ab29e52fc73b508515361/colorlog-5.0.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from clldutils>=1.7.3->segments->phonemizer>=2.2.0->-r requirements.txt (line 7)) (0.8.9)\n",
            "Collecting rfc3986\n",
            "  Downloading https://files.pythonhosted.org/packages/c4/e5/63ca2c4edf4e00657584608bee1001302bbf8c5f569340b78304f2f446cb/rfc3986-1.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: uritemplate>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from csvw>=1.5.6->segments->phonemizer>=2.2.0->-r requirements.txt (line 7)) (3.0.1)\n",
            "Collecting isodate\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 51kB 9.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.1->-r requirements.txt (line 2)) (3.4.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.1->-r requirements.txt (line 2)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.1->-r requirements.txt (line 2)) (3.1.1)\n",
            "Building wheels for collected packages: pyworld\n",
            "  Building wheel for pyworld (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyworld: filename=pyworld-0.3.0-cp37-cp37m-linux_x86_64.whl size=608698 sha256=497bd408d7899e40925fff13996182b0b71fb3e44245c4f1bad544d34bddef25\n",
            "  Stored in directory: /root/.cache/pip/wheels/dc/27/35/dc77501124e514e06bd33bc41253b61dbaea19599c6da2679b\n",
            "Successfully built pyworld\n",
            "Building wheels for collected packages: librosa, bokeh, cardboardlint, umap-learn, pynndescent\n",
            "  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for librosa: filename=librosa-0.7.2-cp37-none-any.whl size=1612903 sha256=1f2941b2016c6dc4d884f06c2193daa9c5c98c5f4fe6032cb809eca22160747a\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/6e/d7/bb93911540d2d1e44d690a1561871e5b6af82b69e80938abef\n",
            "  Building wheel for bokeh (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bokeh: filename=bokeh-1.4.0-cp37-none-any.whl size=23689207 sha256=d5b44c7ac37d1e933b719f00432673226966a96412ff6137be5d34dcdc85c1aa\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/f8/47/09700d9a19cbcbf0b7a3130690b75c0d6ff80fbda0b1774c7c\n",
            "  Building wheel for cardboardlint (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cardboardlint: filename=cardboardlint-1.3.0-cp37-none-any.whl size=51323 sha256=daebdee716e4349657cde6143a31c706b269caa90d3dad06f7ca61d5e8e6f3a4\n",
            "  Stored in directory: /root/.cache/pip/wheels/e6/fe/8e/fbeb2cda877a1f772c0462f9f07eed851f143020947a075ee9\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.1-cp37-none-any.whl size=76569 sha256=b124c0b5a7f9f2a5b4d1276db4e66496a58a798c04f728e50a41e8fd69fbe0d4\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/df/d5/a3691296ff779f25cd1cf415a3af954b987fb53111e3392cf4\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.2-cp37-none-any.whl size=51362 sha256=f5d733f13d8f7f883073756e4152d2b56f055cb7dc3d9fe937e497f390355d76\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/52/4e/4c28d04d144a28f89e2575fb63628df6e6d49b56c5ddd0c74e\n",
            "Successfully built librosa bokeh cardboardlint umap-learn pynndescent\n",
            "\u001b[31mERROR: tensorflow 2.3.1 has requirement numpy<1.19.0,>=1.16.0, but you'll have numpy 1.19.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: panel 0.11.3 has requirement bokeh<2.4.0,>=2.3.0, but you'll have bokeh 1.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pynndescent 0.5.2 has requirement numba>=0.51.2, but you'll have numba 0.48.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: umap-learn 0.5.1 has requirement numba>=0.49, but you'll have numba 0.48.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast, tensorflow-estimator, h5py, tensorflow, llvmlite, numba, librosa, colorlog, rfc3986, isodate, csvw, clldutils, segments, phonemizer, unidecode, attrdict, tensorboardX, bokeh, pysbd, pyworld, nose, cardboardlint, lazy-object-proxy, typed-ast, astroid, isort, mccabe, pylint, pynndescent, umap-learn\n",
            "  Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Found existing installation: tensorflow-estimator 2.5.0\n",
            "    Uninstalling tensorflow-estimator-2.5.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
            "  Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Found existing installation: tensorflow 2.5.0\n",
            "    Uninstalling tensorflow-2.5.0:\n",
            "      Successfully uninstalled tensorflow-2.5.0\n",
            "  Found existing installation: llvmlite 0.34.0\n",
            "    Uninstalling llvmlite-0.34.0:\n",
            "      Successfully uninstalled llvmlite-0.34.0\n",
            "  Found existing installation: numba 0.51.2\n",
            "    Uninstalling numba-0.51.2:\n",
            "      Successfully uninstalled numba-0.51.2\n",
            "  Found existing installation: librosa 0.8.1\n",
            "    Uninstalling librosa-0.8.1:\n",
            "      Successfully uninstalled librosa-0.8.1\n",
            "  Found existing installation: bokeh 2.3.2\n",
            "    Uninstalling bokeh-2.3.2:\n",
            "      Successfully uninstalled bokeh-2.3.2\n",
            "Successfully installed astroid-2.5 attrdict-2.0.1 bokeh-1.4.0 cardboardlint-1.3.0 clldutils-3.9.0 colorlog-5.0.1 csvw-1.11.0 gast-0.3.3 h5py-2.10.0 isodate-0.6.0 isort-4.3.21 lazy-object-proxy-1.6.0 librosa-0.7.2 llvmlite-0.31.0 mccabe-0.6.1 nose-1.3.7 numba-0.48.0 phonemizer-2.2.2 pylint-2.5.3 pynndescent-0.5.2 pysbd-0.3.4 pyworld-0.3.0 rfc3986-1.5.0 segments-2.2.0 tensorboardX-2.2 tensorflow-2.3.1 tensorflow-estimator-2.3.0 typed-ast-1.4.3 umap-learn-0.5.1 unidecode-0.4.20\n",
            "Compiling ./TTS/tts/layers/glow_tts/monotonic_align/core.pyx because it changed.\n",
            "[1/1] Cythonizing ./TTS/tts/layers/glow_tts/monotonic_align/core.pyx\n",
            "/usr/local/lib/python3.7/dist-packages/setuptools/dist.py:694: UserWarning: Usage of dash-separated 'build-lib' will not be supported in future versions. Please use the underscore name 'build_lib' instead\n",
            "  % (opt, underscore_opt))\n",
            "/usr/local/lib/python3.7/dist-packages/setuptools/dist.py:694: UserWarning: Usage of dash-separated 'build-dir' will not be supported in future versions. Please use the underscore name 'build_dir' instead\n",
            "  % (opt, underscore_opt))\n",
            "running develop\n",
            "-- Building version 0.0.8+4132240\n",
            "running egg_info\n",
            "creating TTS.egg-info\n",
            "writing TTS.egg-info/PKG-INFO\n",
            "writing dependency_links to TTS.egg-info/dependency_links.txt\n",
            "writing entry points to TTS.egg-info/entry_points.txt\n",
            "writing requirements to TTS.egg-info/requires.txt\n",
            "writing top-level names to TTS.egg-info/top_level.txt\n",
            "writing manifest file 'TTS.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE.txt'\n",
            "writing manifest file 'TTS.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "building 'TTS.tts.layers.glow_tts.monotonic_align.core' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-3.7\n",
            "creating build/temp.linux-x86_64-3.7/TTS\n",
            "creating build/temp.linux-x86_64-3.7/TTS/tts\n",
            "creating build/temp.linux-x86_64-3.7/TTS/tts/layers\n",
            "creating build/temp.linux-x86_64-3.7/TTS/tts/layers/glow_tts\n",
            "creating build/temp.linux-x86_64-3.7/TTS/tts/layers/glow_tts/monotonic_align\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I/usr/include/python3.7m -c ./TTS/tts/layers/glow_tts/monotonic_align/core.c -o build/temp.linux-x86_64-3.7/./TTS/tts/layers/glow_tts/monotonic_align/core.o\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1822:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./TTS/tts/layers/glow_tts/monotonic_align/core.c:625\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
            " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
            "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "creating build/lib.linux-x86_64-3.7\n",
            "creating build/lib.linux-x86_64-3.7/TTS\n",
            "creating build/lib.linux-x86_64-3.7/TTS/tts\n",
            "creating build/lib.linux-x86_64-3.7/TTS/tts/layers\n",
            "creating build/lib.linux-x86_64-3.7/TTS/tts/layers/glow_tts\n",
            "creating build/lib.linux-x86_64-3.7/TTS/tts/layers/glow_tts/monotonic_align\n",
            "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/./TTS/tts/layers/glow_tts/monotonic_align/core.o -o build/lib.linux-x86_64-3.7/TTS/tts/layers/glow_tts/monotonic_align/core.cpython-37m-x86_64-linux-gnu.so\n",
            "copying build/lib.linux-x86_64-3.7/TTS/tts/layers/glow_tts/monotonic_align/core.cpython-37m-x86_64-linux-gnu.so -> TTS/tts/layers/glow_tts/monotonic_align\n",
            "Creating /usr/local/lib/python3.7/dist-packages/TTS.egg-link (link to .)\n",
            "Adding TTS 0.0.8+4132240 to easy-install.pth file\n",
            "Installing tts-server script to /usr/local/bin\n",
            "\n",
            "Installed /content/TTS_repo\n",
            "Processing dependencies for TTS==0.0.8+4132240\n",
            "error: numba 0.48.0 is installed but numba>=0.49 is required by {'umap-learn'}\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd TTS_repo\n",
        "!git checkout 4132240\n",
        "!pip install -r requirements.txt\n",
        "!python setup.py develop\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zlgi8fPdpRF0"
      },
      "source": [
        "### Define TTS function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "f-Yc42nQZG5A"
      },
      "outputs": [],
      "source": [
        "def interpolate_vocoder_input(scale_factor, spec):\n",
        "    \"\"\"Interpolation to tolarate the sampling rate difference\n",
        "    btw tts model and vocoder\"\"\"\n",
        "    print(\" > before interpolation :\", spec.shape)\n",
        "    spec = torch.tensor(spec).unsqueeze(0).unsqueeze(0)\n",
        "    spec = torch.nn.functional.interpolate(spec, scale_factor=scale_factor, mode='bilinear').squeeze(0)\n",
        "    print(\" > after interpolation :\", spec.shape)\n",
        "    return spec\n",
        "\n",
        "\n",
        "def tts(model, text, CONFIG, use_cuda, ap, use_gl, figures=True):\n",
        "    t_1 = time.time()\n",
        "    # run tts\n",
        "    target_sr = CONFIG.audio['sample_rate']\n",
        "    waveform, alignment, mel_spec, mel_postnet_spec, stop_tokens, inputs =\\\n",
        "     synthesis(model,\n",
        "               text,\n",
        "               CONFIG,\n",
        "               use_cuda,\n",
        "               ap,\n",
        "               speaker_id,\n",
        "               None,\n",
        "               False,\n",
        "               CONFIG.enable_eos_bos_chars,\n",
        "               use_gl)\n",
        "    # run vocoder\n",
        "    mel_postnet_spec = ap._denormalize(mel_postnet_spec.T).T\n",
        "    if not use_gl:\n",
        "        target_sr = VOCODER_CONFIG.audio['sample_rate']\n",
        "        vocoder_input = ap_vocoder._normalize(mel_postnet_spec.T)\n",
        "        if scale_factor[1] != 1:\n",
        "            vocoder_input = interpolate_vocoder_input(scale_factor, vocoder_input)\n",
        "        else:\n",
        "            vocoder_input = torch.tensor(vocoder_input).unsqueeze(0)\n",
        "        waveform = vocoder_model.inference(vocoder_input)\n",
        "    # format output\n",
        "    if use_cuda and not use_gl:\n",
        "        waveform = waveform.cpu()\n",
        "    if not use_gl:\n",
        "        waveform = waveform.numpy()\n",
        "    waveform = waveform.squeeze()\n",
        "    # compute run-time performance\n",
        "    rtf = (time.time() - t_1) / (len(waveform) / ap.sample_rate)\n",
        "    tps = (time.time() - t_1) / len(waveform)\n",
        "    print(waveform.shape)\n",
        "    print(\" > Run-time: {}\".format(time.time() - t_1))\n",
        "    print(\" > Real-time factor: {}\".format(rtf))\n",
        "    print(\" > Time per step: {}\".format(tps))\n",
        "    # display audio\n",
        "    IPython.display.display(IPython.display.Audio(waveform, rate=target_sr))\n",
        "    return alignment, mel_postnet_spec, stop_tokens, waveform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZksegYQepkFg"
      },
      "source": [
        "### Load Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oVa0kOamprgj"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import torch\n",
        "import time\n",
        "import IPython\n",
        "\n",
        "# for some reason TTS installation does not work on Colab\n",
        "sys.path.append('TTS_repo')\n",
        "\n",
        "from TTS.utils.io import load_config\n",
        "from TTS.utils.audio import AudioProcessor\n",
        "from TTS.tts.utils.generic_utils import setup_model\n",
        "from TTS.tts.utils.text.symbols import symbols, phonemes, make_symbols\n",
        "from TTS.tts.utils.synthesis import synthesis\n",
        "from TTS.tts.utils.io import load_checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EY-sHVO8IFSH"
      },
      "outputs": [],
      "source": [
        "# runtime settings\n",
        "use_cuda = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_1aIUp2FpxOQ"
      },
      "outputs": [],
      "source": [
        "# model paths\n",
        "TTS_MODEL = \"tts_model.pth.tar\"\n",
        "TTS_CONFIG = \"config.json\"\n",
        "VOCODER_MODEL = \"vocoder_model.pth.tar\"\n",
        "VOCODER_CONFIG = \"config_vocoder.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CpgmdBVQplbv"
      },
      "outputs": [],
      "source": [
        "# load configs\n",
        "TTS_CONFIG = load_config(TTS_CONFIG)\n",
        "VOCODER_CONFIG = load_config(VOCODER_CONFIG)\n",
        "\n",
        "TTS_CONFIG.audio['stats_path'] = \"./scale_stats.npy\"\n",
        "VOCODER_CONFIG.audio['stats_path'] = \"./scale_stats_vocoder.npy\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zmrQxiozIUVE",
        "outputId": "aef5f72a-eebe-4219-eefe-72c84cbe614e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > Setting up Audio Processor...\n",
            " | > sample_rate:22050\n",
            " | > resample:False\n",
            " | > num_mels:80\n",
            " | > min_level_db:-100\n",
            " | > frame_shift_ms:None\n",
            " | > frame_length_ms:None\n",
            " | > ref_level_db:20\n",
            " | > fft_size:1024\n",
            " | > power:1.5\n",
            " | > preemphasis:0.0\n",
            " | > griffin_lim_iters:60\n",
            " | > signal_norm:True\n",
            " | > symmetric_norm:True\n",
            " | > mel_fmin:50.0\n",
            " | > mel_fmax:7600.0\n",
            " | > spec_gain:1.0\n",
            " | > stft_pad_mode:reflect\n",
            " | > max_norm:4.0\n",
            " | > clip_norm:True\n",
            " | > do_trim_silence:True\n",
            " | > trim_db:60\n",
            " | > do_sound_norm:False\n",
            " | > stats_path:./scale_stats.npy\n",
            " | > hop_length:256\n",
            " | > win_length:1024\n"
          ]
        }
      ],
      "source": [
        "# load the audio processor\n",
        "ap = AudioProcessor(**TTS_CONFIG.audio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8fLoI4ipqMeS",
        "outputId": "f90c4c61-87b9-4b62-b057-3fc68e74baa1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > Using model: Tacotron2\n",
            " > Model r:  2\n"
          ]
        }
      ],
      "source": [
        "# LOAD TTS MODEL\n",
        "# multi speaker\n",
        "speakers = []\n",
        "speaker_id = None\n",
        "\n",
        "if 'characters' in TTS_CONFIG.keys():\n",
        "    symbols, phonemes = make_symbols(**TTS_CONFIG.characters)\n",
        "\n",
        "# load the model\n",
        "num_chars = len(phonemes) if TTS_CONFIG.use_phonemes else len(symbols)\n",
        "model = setup_model(num_chars, len(speakers), TTS_CONFIG)\n",
        "\n",
        "# load model state\n",
        "model, _ =  load_checkpoint(model, TTS_MODEL, use_cuda=use_cuda)\n",
        "model.eval();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zKoq0GgzqzhQ",
        "outputId": "7b5682cf-7329-4ce7-dee1-9e92cf921b64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > Generator Model: fullband_melgan_generator\n",
            "scale_factor: [1, 1.08843537414966]\n",
            " > Setting up Audio Processor...\n",
            " | > sample_rate:24000\n",
            " | > resample:False\n",
            " | > num_mels:80\n",
            " | > min_level_db:-100\n",
            " | > frame_shift_ms:None\n",
            " | > frame_length_ms:None\n",
            " | > ref_level_db:0\n",
            " | > fft_size:1024\n",
            " | > power:None\n",
            " | > preemphasis:0.0\n",
            " | > griffin_lim_iters:None\n",
            " | > signal_norm:True\n",
            " | > symmetric_norm:True\n",
            " | > mel_fmin:50.0\n",
            " | > mel_fmax:7600.0\n",
            " | > spec_gain:1.0\n",
            " | > stft_pad_mode:reflect\n",
            " | > max_norm:4.0\n",
            " | > clip_norm:True\n",
            " | > do_trim_silence:True\n",
            " | > trim_db:60\n",
            " | > do_sound_norm:False\n",
            " | > stats_path:./scale_stats_vocoder.npy\n",
            " | > hop_length:256\n",
            " | > win_length:1024\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-b79387c4b0c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"scale_factor: {scale_factor}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0map_vocoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudioProcessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mVOCODER_CONFIG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'audio'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mvocoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/TTS_repo/TTS/utils/audio.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sample_rate, resample, num_mels, min_level_db, frame_shift_ms, frame_length_ms, hop_length, win_length, ref_level_db, fft_size, power, preemphasis, signal_norm, symmetric_norm, max_norm, mel_fmin, mel_fmax, spec_gain, stft_pad_mode, clip_norm, griffin_lim_iters, do_trim_silence, trim_db, do_sound_norm, stats_path, **_)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;31m# setup scaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstats_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mmel_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmel_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinear_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinear_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_scaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmel_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinear_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinear_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/TTS_repo/TTS/utils/audio.py\u001b[0m in \u001b[0;36mload_stats\u001b[0;34m(self, stats_path)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;31m### Mean-STD scaling ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#pylint: disable=unexpected-keyword-arg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0mmel_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mel_mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mmel_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mel_std'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './scale_stats_vocoder.npy'"
          ]
        }
      ],
      "source": [
        "from TTS.vocoder.utils.generic_utils import setup_generator\n",
        "\n",
        "# LOAD VOCODER MODEL\n",
        "vocoder_model = setup_generator(VOCODER_CONFIG)\n",
        "vocoder_model.load_state_dict(torch.load(VOCODER_MODEL, map_location=\"cpu\")[\"model\"])\n",
        "vocoder_model.remove_weight_norm()\n",
        "vocoder_model.inference_padding = 0\n",
        "\n",
        "# scale factor for sampling rate difference\n",
        "scale_factor = [1,  VOCODER_CONFIG['audio']['sample_rate'] / ap.sample_rate]\n",
        "print(f\"scale_factor: {scale_factor}\")\n",
        "\n",
        "ap_vocoder = AudioProcessor(**VOCODER_CONFIG['audio'])\n",
        "if use_cuda:\n",
        "    vocoder_model.cuda()\n",
        "vocoder_model.eval();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ws_YkPKsLgo-"
      },
      "source": [
        "## Run Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FuWxZ9Ey5Puj"
      },
      "outputs": [],
      "source": [
        "sentence =  \"Bill got in the habit of asking himself ‚ÄúIs that thought true?‚Äù and if he wasn‚Äôt absolutely certain it was, he just let it go.\"\n",
        "align, spec, stop_tokedns, wav = tts(model, sentence, TTS_CONFIG, use_cuda, ap, use_gl=False, figures=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}